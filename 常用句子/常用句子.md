## 该部分主要记录一些常用的句子


>*  **是什么而不是什么**  
    中文：据我们所知，这是第一个直接用深度卷积网络而不是通过学习网络参数来捕获先验信息的研究  
    英文：To the best of our knowledge, this is the first study that directly investigates the prior **captured by deep convolutional generative network** **independently of learning the network parameters for images**.  
    解释：两个定语，两个定语可以直接叠加：  
          1) was captured by the deep convolutional generative network  
          2) was catpured independently of learning the network parameters for images

>*  **除了什么任务，我们的方法在另一个领域也有重要的应用**  
    中文：除了图像恢复任务，我们的方法还有另外一个重要的应用：理解包含在deep cnn激活中的信息  
    英文：**In addition to** standard image restoration tasks, **we show an application of our technique to** understanding **the information contained within** the activations of deep neural networks.  

>*  **不是而是，避免了由什么引起的错误/偏见**  
    中文：由于像TV norm之类的新的正则器是手工设计的而不是从数据中学习到的，可视化结果避免了由使用学习到的强正则化器引起的偏置。  
    英文： Since the new regularizer, like the TV norm, **is not** learned from data **but is** entirely handcrafted, the resulting visualizations **avoid potential bias arising from** the use of powerful learned regularizers.  

> * **通过什么被应用到...**  
    中文：通过学习一个将随机向量z映射到x的生成器/解码器将深度网络应用到图像生成  
    英文：Deep networks **are applied to** image generation **by** **learning a generator/decoder networks x = fθ(z)** that map a random code vector z to an image x.  
    
>*  **什么有稳定的提升**  
    中文：通过引入去噪组件，性能有持续的提升  
    英文： There is a consistent performance improvement by introducted by the denoising blocks.  

>*  **提升了多少幅度，从多少到多少**  
    中文：它提升了Resnet-152 baseline的准确率3.2%，从52.5%到55.7%  
    英文： It improves the accuracy of ResNet-152 baseline by 3.2% from 52.5% to 55.7% (Figure 6, right).  
    
>*  **一种方法实现了多少，其counterpart实现了多少**  
    中文：ResNet-152 baseline实现了多少准确率，它的counterpart比它提升了多少，实现了多少准确率  
    英文： ResNet-152 baseline has 39.2% accuracy, and its denoising counterpart is 3.4% better, achieving 42.6%  
    
>*  **如果不特别声明，默认的是...**  
    中文：在此论文中，我们默认使用了A，如果不特别声明  
    英文：We use A by default in this paper unless noted.

>* **缩小了什么与什么之间的差距**    
    中文：它同时缩小了两类图像恢复方法的鸿沟：使用deep cnn进行学习的方法和基于人工图像特征的非学习方法  
    英文：It also **bridges the gap between** two very popular families of image restoration methods: learning-based methods using deep convolutional networks and learning-free methods based on handcrafted image priors such as self-similarity.  
    解释： methods复数，networks复数，such as self-similarity做最后的定语
>*  **为了清楚，有些地方在图中没有体现出来**   
    中文：为了清楚，有些地方在图中没有体现出来  
    英文：For clarity, * and * are not included.  
